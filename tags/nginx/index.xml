<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nginx on Blog | Federico Marani</title>
    <link>/tags/nginx/</link>
    <description>Recent content in Nginx on Blog | Federico Marani</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</copyright>
    <lastBuildDate>Sun, 17 Oct 2010 13:55:49 +0000</lastBuildDate>
    <atom:link href="/tags/nginx/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>CDN Optimizations</title>
      <link>/blog/cdn-optimizations/</link>
      <pubDate>Sun, 17 Oct 2010 13:55:49 +0000</pubDate>
      
      <guid>/blog/cdn-optimizations/</guid>
      <description>&lt;p&gt;One of our most trafficked website is on average sustaining 300000 page views per day. Each page has normally a considerable amount of JavaScript, some of it activated only after the whole DOM has been loaded.&lt;/p&gt;

&lt;p&gt;Considering that every page has on average 20-30 images coming from our image server, every small optimization to it has an avalanche effect on all the other parts of the system.&lt;/p&gt;

&lt;p&gt;I already described the infrastructure in the Nginx post. What i changed from that configuration is all I/O related, trying to minimize writes on the disk and internal connections to Apache, but the biggest change is the duration of nginx cache which is now 6 hours instead of one hour. The impact on the main site has been remarkable.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;../../attachments/nginx-1-to-6h-caching.jpg&#34; alt=&#34;nginx graph&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Nginx rocks</title>
      <link>/blog/nginx-rocks/</link>
      <pubDate>Sun, 03 Oct 2010 16:09:47 +0000</pubDate>
      
      <guid>/blog/nginx-rocks/</guid>
      <description>&lt;p&gt;I have installed Nginx some time ago on one of our busiest servers on our partner&amp;rsquo;s networks, i promised i would have blogged about this and now it&amp;rsquo;s about time. This server only serves images of products sold thorugh our e-commerce site. The first configuration was only a simple web server which was serving already resized images directly, due to the massive amount of images and the cleaning of it which was taking days, i decided to use Nginx in reverse proxy mode. I have to say i am still impressed, after 6-7 months, about this software. I&amp;rsquo;ve never had to restart it one time except for little configuration tweaks.&lt;/p&gt;

&lt;p&gt;This software is so good that we decided to put images that compose emails on this server as well. This is kind of critical because, after the nightly mail-out, there are 5-6 hours in the morning with constants spikes of traffic. Again, absolutely no side-effects, Nginx relentlessly serves gigabytes and gigabytes of images as if nothing happened.&lt;/p&gt;

&lt;p&gt;This is our configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# FIRST TIER TO ANSWER HTTP REQUESTS FOR IMAGES
# SECOND TIER IS APACHE

user  apache;
worker_processes  4; // same as number of cpu cores

error_log  logs/error.log;
pid        logs/nginx.pid;

events {
worker_connections  512;
}

http {
include       mime.types;
default_type  application/octet-stream;

log_format  main  &#39;$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; &#39;
&#39;$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; &#39;
&#39;&amp;quot;$http_user_agent&amp;quot; &amp;quot;$http_x_forwarded_for&amp;quot;&#39;;

# access_log  logs/access.log  main;
access_log off;

sendfile        on;
keepalive_timeout  65;

upstream imageserver {
server 127.0.0.1:81 fail_timeout=120s;
}

proxy_cache_path /opt/nginx/cache levels=2:2:2 keys_zone=imagecache:10m;
proxy_temp_path /opt/nginx/cache_temp;

server {
listen       80;
server_name  NAME.DOMAIN.COM;
#access_log  logs/host.access.log  main; //disabled for speed

root /home/website/root;
index index.php index.html index.htm;

gzip on;
gzip_disable &amp;quot;msie6&amp;quot;;
gzip_disable &amp;quot;Lynx&amp;quot;;
gzip_comp_level 8;
gzip_min_length 1000;
gzip_proxied any;
gzip_types text/plain text/css application/x-javascript text/xml application/xml application/xml+rss text/javascript;

location /nginx_status {
stub_status on;
access_log   off;
allow 127.0.0.1;
deny all;
}

location /images {
expires 15d;

client_max_body_size 8m;

proxy_redirect off;
proxy_set_header Host $host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_pass_header Set-Cookie;

proxy_cache imagecache;
proxy_cache_valid 200 302 60m;
proxy_cache_valid 404 5m;

proxy_cache_use_stale timeout;
proxy_connect_timeout 40;
proxy_read_timeout 80;

# REGEX to filter out bad image urls
if ($uri ~* &amp;quot;.*/([a-z]+)/[a-z0-9\-]+/([a-z0-9\-]+)/([0-9]+)/([0-9]+)/([a-z0-9\-]*)/([a-z0-9\-]+)\.jpg$&amp;quot;) {     #case insensitive
proxy_pass http://imageserver;
}

}

error_page   500 502 503 504  /50x.html;
location = /50x.html {
root   html;
}

location ~ /\.ht {
deny  all;
}
}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This configuration is able to serve a constant flux of 1.5Mb/s, which i reckon is about 200 requests/sec for an average file of 3Kb. Most of the requests are served directly by Nginx, some others go through to Apache which has in average 200 connnections opened.&lt;/p&gt;

&lt;p&gt;The version of nginx used is 0.7.65 compiled from sources. This because new 0.7 has an improved reverse caching module which was needed for this.&lt;/p&gt;

&lt;p&gt;EDIT: I&amp;rsquo;ve been doing some statistics on a recent normal day: 100Gb of traffic and 25-30 million images transferred. Server load was below the limit and most of it coming from Apache. Not bad at all!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>