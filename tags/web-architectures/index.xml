<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>web architectures on Blog | Federico Marani</title>
    <link>/tags/web-architectures/</link>
    <description>Recent content in web architectures on Blog | Federico Marani</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</copyright>
    <lastBuildDate>Wed, 15 May 2019 17:54:18 +0100</lastBuildDate>
    
	<atom:link href="/tags/web-architectures/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Evolution of Single Sign On</title>
      <link>/blog/evolution-of-single-sign-on/</link>
      <pubDate>Wed, 15 May 2019 17:54:18 +0100</pubDate>
      
      <guid>/blog/evolution-of-single-sign-on/</guid>
      <description>Single sign on is a very common requirement for organizations with many employees. Once you reach a certain stage and new employees are onboarded regularly, you need a smooth process for this. Similarly, employee churn becomes an ordinary event, and you have to make sure that people that do not work for the company anymore are taken out from your user database and their accesses revoked.
Before the advent of SSO (or LDAP/AD), users were created and managed on the various systems separately.</description>
    </item>
    
    <item>
      <title>Working with caches and Memcache</title>
      <link>/blog/working-with-memcache/</link>
      <pubDate>Wed, 14 Jan 2015 11:45:46 +0000</pubDate>
      
      <guid>/blog/working-with-memcache/</guid>
      <description>The traditional use of Memcache is to cache things like computations that take some time or result coming from external system with limited throughput. Examples of these may be database queries (sometimes long to compute), search queries coming from dedicated search services or simply feeds from other sites that don&amp;rsquo;t change often.
Memcache is both a cache system and a separate component in your system architecture, so it is very important to understand the implications.</description>
    </item>
    
    <item>
      <title>Ubuntu on EC2, the simple way.</title>
      <link>/blog/ubuntu-on-ec2-the-simple-way/</link>
      <pubDate>Sun, 06 May 2012 11:39:37 +0000</pubDate>
      
      <guid>/blog/ubuntu-on-ec2-the-simple-way/</guid>
      <description>Problem Sometime ago I had to run a statistical software on some data, the computation was really expensive, it was impractical to run it on my small laptop as it would hung for hours waiting for a result to come up. I thought about running it on Amazon.
Solution Amazon EC2 is a virtual machine hosting service, also known as IaaS. Quite similar to Linode or Rackspace. Payment here is per hour, differently from Linode&amp;hellip; slightly on the expensive side i might add, but top-end VMs are quite powerful.</description>
    </item>
    
    <item>
      <title>How small websites become big</title>
      <link>/blog/how-small-websites-become-big/</link>
      <pubDate>Wed, 30 Mar 2011 00:42:56 +0000</pubDate>
      
      <guid>/blog/how-small-websites-become-big/</guid>
      <description>There is no secret recipe, there is no list of check boxes to tick&amp;hellip; just some guidelines. Part of these lessons have been learned in the hard way, part because i have been always taught that if you want to be the best, you have to copy the best. There is plenty of literature on Internet about this&amp;hellip; read, understand and copy.
I think the art of building high-traffic websites is part about the code, but mostly about your web architecture and the tools you use.</description>
    </item>
    
    <item>
      <title>CDN Optimizations</title>
      <link>/blog/cdn-optimizations/</link>
      <pubDate>Sun, 17 Oct 2010 13:55:49 +0000</pubDate>
      
      <guid>/blog/cdn-optimizations/</guid>
      <description>One of our most trafficked website is on average sustaining 300000 page views per day. Each page has normally a considerable amount of JavaScript, some of it activated only after the whole DOM has been loaded.
Considering that every page has on average 20-30 images coming from our image server, every small optimization to it has an avalanche effect on all the other parts of the system.
I already described the infrastructure in the Nginx post.</description>
    </item>
    
    <item>
      <title>Nginx rocks</title>
      <link>/blog/nginx-rocks/</link>
      <pubDate>Sun, 03 Oct 2010 16:09:47 +0000</pubDate>
      
      <guid>/blog/nginx-rocks/</guid>
      <description>I have installed Nginx some time ago on one of our busiest servers on our partner&amp;rsquo;s networks, i promised i would have blogged about this and now it&amp;rsquo;s about time. This server only serves images of products sold thorugh our e-commerce site. The first configuration was only a simple web server which was serving already resized images directly, due to the massive amount of images and the cleaning of it which was taking days, i decided to use Nginx in reverse proxy mode.</description>
    </item>
    
  </channel>
</rss>