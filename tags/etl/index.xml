<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>etl on Blog | Federico Marani</title>
    <link>/tags/etl/</link>
    <description>Recent content in etl on Blog | Federico Marani</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</copyright>
    <lastBuildDate>Sun, 18 Jun 2017 14:44:35 +0100</lastBuildDate>
    
	<atom:link href="/tags/etl/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Moving data in bulk in and out of Postgresql</title>
      <link>/blog/moving-data-in-and-out-of-postgresql/</link>
      <pubDate>Sun, 18 Jun 2017 14:44:35 +0100</pubDate>
      
      <guid>/blog/moving-data-in-and-out-of-postgresql/</guid>
      <description>Postgresql is a database, and its primary goal is to be efficient when storing and querying information that is stored on disk. Same primary goal of many other databases, with the minor exception of in-memory databases. Postgresql however is a very flexible and extensible system, and in the last few years a lot of extensions came out, one of which is Foreign Data Wrappers.
With Postgres foreign data wrappers, it is very easy to move data in and out of it from other databases.</description>
    </item>
    
    <item>
      <title>How Apache Airflow works</title>
      <link>/blog/how-apache-airflow-works/</link>
      <pubDate>Wed, 31 May 2017 10:17:15 +0100</pubDate>
      
      <guid>/blog/how-apache-airflow-works/</guid>
      <description>(continuing from a previous article)
Scheduler Airflow is made up of mainly two components: webserver and scheduler. The webserver is the main way to interact with Airflow, although some commands can be issued from the command line, such as setting variables or connection credentials. The scheduler is the component that is in charge of executing whatever needs to be executed at a specific time and using a configurable strategy.</description>
    </item>
    
    <item>
      <title>Introduction to Apache Airflow</title>
      <link>/blog/intro-to-apache-airflow/</link>
      <pubDate>Tue, 16 May 2017 10:17:15 +0100</pubDate>
      
      <guid>/blog/intro-to-apache-airflow/</guid>
      <description>Background Apache Airflow is a tool to work with complex and recurring workflows. Workflows is a more formal term to describe scripts like cronjobs. Scripts constitute of a series of tasks, sometimes with retry mechanism attached to it.
A tool like this is used in data-intensive environments with background jobs that need to run everyday. These background scripts do extraction, enrichment and other transformations to a dataset. Most workflow software gives you a structure to use when writing your scripts, so they are able to distinguish between steps and manage their interdependencies.</description>
    </item>
    
  </channel>
</rss>